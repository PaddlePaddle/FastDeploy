# Copyright (c) 2022 PaddlePaddle Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
from __future__ import absolute_import
import logging
import os
import sys


def is_built_with_gpu() -> bool:
    return True if "@WITH_GPU@" == "ON" else False


def is_built_with_ort() -> bool:
    return True if "@ENABLE_ORT_BACKEND@" == "ON" else False


def is_built_with_trt() -> bool:
    return True if "@ENABLE_TRT_BACKEND@" == "ON" else False


def is_built_with_paddle() -> bool:
    return True if "@ENABLE_PADDLE_BACKEND@" == "ON" else False

def is_built_with_openvino() ->bool:
    return True if "@ENABLE_OPENVINO_BACKEND@" == "ON" else False


def get_default_cuda_directory() -> str:
    if not is_built_with_gpu():
       return ""
    return r"@CUDA_DIRECTORY@".strip()


def add_dll_search_dir(dir_path):
    os.environ["path"] = dir_path + ";" + os.environ["path"]
    sys.path.insert(0, dir_path)
    if sys.version_info[:2] >= (3, 8):
        os.add_dll_directory(dir_path)


def load_dso_or_dll(dso_or_dll_name=None) -> bool:
    from ctypes import cdll
    if dso_or_dll_name is None:
        dso_or_dll_name = "fastdeploy.dll"
    try:
        dso_or_dll = cdll.LoadLibrary(dso_or_dll_name)
        del dso_or_dll
        print(f"[FastDeploy][INFO]:  Successfully pre load {dso_or_dll_name}.")
        return True
    except Exception as e:
        print(f"[FastDeploy][ERROR]: Can not pre load dll/dso: {dso_or_dll_name}. {e}")
        return False


def try_pre_load_fastdeploy_dll() -> bool:
    # Try pre-load fastdeploy dll in windows to
    # make sure the added custom dll directory
    # has been activated. Reference:
    # [1] https://github.com/conda/conda/issues/10897
    # [2] https://github.com/dhermes/bezier/issues/237
    # TODO(qiuyanjun): add Linux and Mac *.so|*.dylib check
    return load_dso_or_dll("fastdeploy.dll")


def try_pre_load_cudart_dll(cuda_version: str) -> bool:
    if cuda_version is None:
        print("[FastDeploy][ERROR]: CUDA version can not be NoneTpye.")
        return False
    major_version_number = int(cuda_version.strip().strip("v").split(".")[0])
    # TODO(qiuyanjun): add Linux and Mac cudart *.so|*.dylib check
    return load_dso_or_dll(f"cudart64_{major_version_number}0.dll")


def add_cuda_shared_lib_dir_windows():
    if is_built_with_gpu():
        # if FastDeploy built with gpu and want to run
        # in windows, we need to add CUDA_DIRECTORY into
        # dll search paths to make sure FastDeploy.dll
        # can link cudart correctly. we search the
        # default path firstly and try to add into
        # paths. User should set it manually if the
        # cuda toolkit is not locate in the default
        # path we assume.
        base_url = "https://github.com/PaddlePaddle/FastDeploy/blob/"
        default_cuda_dir = get_default_cuda_directory()
        default_cuda_version = os.path.basename(default_cuda_dir)  # v11.2
        cuda_shared_lib_dir = os.path.join(default_cuda_dir, "bin")
        custom_cuda_envs = ["CUDA_DIRECTORY", "CUDA_HOME", "CUDA_ROOT", "CUDA_PATH"]
        custom_cuda_dir = "NOTFOUNDED"
        if not os.path.exists(cuda_shared_lib_dir):
            # try to get cuda directory from user's local env
            for custom_env in custom_cuda_envs:
                custom_cuda_dir = os.getenv(custom_env, "NOTFOUNDED")
                custom_cuda_dir = custom_cuda_dir.strip().split(";")[0]
                if os.path.exists(custom_cuda_dir) and custom_cuda_dir != "NOTFOUNDED":
                    break
            if not os.path.exists(custom_cuda_dir) or custom_cuda_dir == "NOTFOUNDED":
                logging.warnings.warn(f"\n--- FastDeploy was built with gpu, \
                    \n--- but the default cuda directory does not exists. \
                    \n--- Please setup one of {custom_cuda_envs} manually, \
                    \n--- this path should look like: {default_cuda_dir}. \
                    \n--- Check FAQ: {base_url + 'develop/docs/FAQ.md'}")
                return
            # path to cuda dlls
            cuda_shared_lib_dir = os.path.join(custom_cuda_dir, "bin")
        add_dll_search_dir(cuda_shared_lib_dir)
        # try pre load cudart with major version, e.g 11.x/10.x
        if not try_pre_load_cudart_dll(default_cuda_version):
            custom_cuda_version = os.path.basename(custom_cuda_dir)
            logging.warnings.warn(
                f"\n--- FastDeploy was built with CUDA version {default_cuda_version}, \
                \n--- but found custom CUDA version {custom_cuda_version} at {custom_cuda_dir} \
                \n--- Please setup one of {custom_cuda_envs} manually, \
                \n--- this path should look like: {default_cuda_dir}. \
                \n--- Check FAQ: {base_url + 'develop/docs/FAQ.md'}")
            return
        print(f"[FastDeploy][INFO]:  Successfully found CUDA ToolKit from -> {cuda_shared_lib_dir}")


if os.name == "nt":
    add_cuda_shared_lib_dir_windows()
    current_path = os.path.abspath(__file__)
    dirname = os.path.dirname(current_path)
    third_libs_dir = os.path.join(dirname, "libs")
    add_dll_search_dir(third_libs_dir)
    for root, dirs, filenames in os.walk(third_libs_dir):
        for d in dirs:
            if d == "lib" or d == "bin":
                add_dll_search_dir(os.path.join(dirname, root, d))
    try_pre_load_fastdeploy_dll()


try:
    from .libs.@PY_LIBRARY_NAME@ import *
except:
    raise RuntimeError("FastDeploy initalized failed!")


def TensorInfoStr(tensor_info):
    message = "TensorInfo(name : '{}', dtype : '{}', shape : '{}')".format(
        tensor_info.name, tensor_info.dtype, tensor_info.shape)
    return message


def RuntimeOptionStr(runtime_option):
    attrs = dir(runtime_option)
    message = "RuntimeOption(\n"
    for attr in attrs:
        if attr.startswith("__"):
            continue
        if hasattr(getattr(runtime_option, attr), "__call__"):
            continue
        message += "  {} : {}\t\n".format(attr, getattr(runtime_option, attr))
    message.strip("\n")
    message += ")"
    return message


TensorInfo.__repr__ = TensorInfoStr
RuntimeOption.__repr__ = RuntimeOptionStr
